---
title: "5. Hidden Markov Model"
date: 2024-10-07 00:01:00 +0900
categories: [학부 수업, (3-2) Machine Learning]
tags: [machine learning]     # TAG names should always be lowercase
math: true
mermaid: true
---

### [5.1] Markov Model
---
- 어떤 상태들이 존재하고, 그 상태의 변화에 따른 확률(전이 확률)이 있는 모델
- 결합 확률 (Joint Probability) 계산 모델
- 연쇄 규칙과 마코프 가정을 이용해 결합 확률을 단순화하여 결합 확률을 근사화시키는 모델

#### Markov Assumption
결합 확률을 계산하기 위해서는 $y_1$이 일어날 확률, $y_1$이 일어났을 때 $y_2$가 일어날 확률, $y_1, y_2$가 일어났을 때 $y_3$가 일어날 확률 ... 들을 곱해서 구해야 한다. 이전 상태들을 모두 고려해서 계산해보면 확률적으로 너무 낮은 값이 나와 $0$에 근사하게 될 것이다. 따라서 현실적으로는 이런 연쇄 규칙을 적용하기가 어렵다.

$$ 
P(y_1, y_2, \dots, y_t) = P(y_1) P(y_2 | y_1) P(y_3 | y_1, y_2) \dots P(y_t | y_1, y_2, \dots, y_{t-1}) 
$$

이를 해결하기 위해 **Markov 가정**을 하게 된다. 바로 앞에 한 개만 나왔을 때의 확률을 구하는 것을 **1차 마코프 가정 을 한 모델(Bi-gram 모델)** 이라고 한다. 두 개를 가지고 하면 2차 마코프 모델 (Tri-gram 모델)이라고 한다. 1차 마코프 가정을 하여 결합 확률을 다시 쓰면 아래와 같다.

$$
\approx P(y_1) P(y_2 | y_1) P(y_3 | y_2) \dots P(y_t | y_{t-1})
$$

이 정도로 근사하면 $0$보다 크게 하여 값을 구할 수 있게 된다.

#### Markov Model
State가 $\text{Rainy, Cloudy, Sunny}$가 존재하고 각각의 Transition Probability (전이 확률)이 아래와 같다고 하자.

![5-1](assets/img/school_ml/ml5-1.png)

**1차 마코프 가정을 한 모델이라고 할 때, 날씨가 $\text{Rainy, Rainy, Sunny, Cloudy}$ 일 확률을 구하시오.** <br/>
- State: $$\{S_1 = \text{Rainy}, S_2 = \text{Cloudy}, S_3 = \text{Sunny} \}$$
- 구하고자 하는 값: $P(S_1, S_1, S_3, S_2)$
- 1차 마코프 가정: $P(S_1) P(S_1\vert S_1) P(S_3\vert S_1) P(S_2\vert S_3) = 1 \times 0.4 \times 0.3 \times 0.1 = 0.012$ (시작 확률은 $1$이라 가정)

### [5.2] Hidden Markov Model
---
상태를 직접 관측할 수 없고 숨어있는 경우를 의미한다. 그 대신 상태를 예측하는데 도움이 되는 feature만을 관측할 수 있다. 아래 예시를 통해 이해해보자.

> 나는 집 밖의 날씨를 알 수 없고, 상대방이 장화(Boots)를 신고 왔는지, 운동화(Sports)를 신고 왔는지만 관측할 수 있다. 그리고 각 신발을 신었을 때 Rainy, Cloudy, Sunny일 확률들(Observation Probability)을 알고 있다. 상대방이 $B, B, S, S$로 신고 왔을 때 가장 확률이 높도록 날씨를 예측하려면 어떻게 해야 할까?
{: .prompt-info}

![5-2](assets/img/school_ml/ml5-2.png){: style="margin-left: auto; margin-right: auto; width: 50%;"}

- $t$번째 관측한 값을 $x_t$ 라고 표현하고 그에 해당하는 label을 $y_t$라고 한다. 위의 예시에서 $x_1$은 $B$ 이고 $y_1$이 Rainy, Cloudy, Sunny 중 무엇일지 찾는 것이다. 이 과정을 모든 날에 대해 동시에 생각해야 하므로, $x_1, x_2, \dots x_t$ 전체를 $x_{1 \sim t}$로,  $y_1, y_2, \dots y_t$ 전체를 $y_{1 \sim t}$로 표현한다.
- HMM의 목표는 $P(x_{1\sim t}, y_{1\sim t})$ 를 최대로 만드는 $y_1, y_2, \dots, y_t$ 값들을 찾는 것이다.
- 마코프 가정이 없을 경우 위의 식은 $P(x_1 \vert y_{1\sim t}) P(x_2 \vert y_{1\sim t}) \dots P(x_t \vert y_{1\sim t})$와 같이 모든 $y$가 일어났을 때 확률로 구해야 하지만, 이렇게 하면 확률이 거의 $0$에 수렴한다.
- 따라서 **1차 마코프 가정**을 통해 $x_i$는 $y_i$ 상태일 때 어떤 확률로 나타나는지만 보겠다고 가정한다. 이를 독립 가정이라고 한다.
- 최종적으로 구해야 하는 것은 아래와 같다.

$$\operatorname*{argmax}_{y_{1\sim t}} \prod_{i=1}^{t} \left( P(y_i | y_{i-1}) P(x_i | y_i) \right)$$

- $P(y_i \vert y_{i-1})$는 Transition Probability (전이 확률)로 다음 상태로 이동할 확률을 의미한다.
- $P(x_i \vert y_i)$는 Observation Probability (관측 확률)로 해당 상태에서 관측이 될 확률을 의미한다.

### [5.3] Viterbi Algorithm
---
직접 모든 경로를 고려하지 않고도 빠른 시간 내의 최적의 경로를 찾는 알고리즘이다. 

![5-3](assets/img/school_ml/ml5-3.png)

문제: 좌측의 HMM 모델이 주어졌을 때, $\text{R R G B}$를 관측했을 때 각각이 어떤 상태일 확률이 제일 높은지를 구하시오.
- 그래프는 위에서부터 $1, 2, 3$번 상태를 의미하고 각각의 state로 이동할 전이 확률을 작성하였다. 그리고 각 state에서의 RGB 각각의 관측 확률도 작성하였다.
- $\pi$는 각 상태의 시작확률을 의미한다. $1$번에서 시작할 확률이 $1$이고, $2, 3$번에서는 $0$임을 보여준다.
- Viterbi 알고리즘의 각 과정은 전이 확률과 관측 확률을 곱해서 그 중 가장 큰 경로만을 구하는 것이 목표이다. 이때 다음 단계의 확률은 이전 단계의 확률에 전이 확률과 관측 확률을 곱해서 구해야 한다.

##### 첫번째 $R$
- 시작을 $1$번 상태에서 하고 $R$이 나올 확률: $1 \times 0.6 = 0.6$
- 시작을 $2$번 상태에서 하고 $R$이 나올 확률: $0 \times 0.2 = 0.0$
- 시작을 $3$번 상태에서 하고 $R$이 나올 확률: $0 \times 0.0 = 0.0$


##### 두번째 $R$
- 도착점이 $1$번 상태일 때 $R$이 나올 확률: $0.18$
  - $[1 \rightarrow 1]$ $0.6 \times 0.5 \times 0.6 = 0.180$
  - $[2 \rightarrow 1]$ 없음
  - $[3 \rightarrow 1]$ 없음
- 도착점이 $2$번 상태일 때 $R$이 나올 확률: $0.048$
  - $[1 \rightarrow 2]$ $0.6 \times 0.4 \times 0.2 = 0.048$
  - $[2 \rightarrow 2]$ $0 \times 0.6 \times 0.2 = 0.000$
  - $[3 \rightarrow 2]$ 없음
- 도착점이 $3$번 상태일 때 $R$이 나올 확률: $0$
  - $[1 \rightarrow 3]$ $0.6 \times 0.1 \times 0.0 = 0.000$
  - $[2 \rightarrow 3]$ $0 \times 0.4 \times 0.0 = 0.000$
  - $[3 \rightarrow 3]$ 없음

##### 세번째 $G$
- 도착점이 $1$번 상태일 때 $G$가 나올 확률: $0.018$
  - $[1 \rightarrow 1]$ $0.18 \times 0.5 \times 0.2 = 0.0180$
  - $[2 \rightarrow 1]$ 없음
  - $[3 \rightarrow 1]$ 없음
- 도착점이 $2$번 상태일 때 $G$가 나올 확률: $0.036$
  - $[1 \rightarrow 2]$ $0.18 \times 0.4 \times 0.5 = 0.0360$
  - $[2 \rightarrow 2]$ $0.048 \times 0.6 \times 0.5 = 0.0144$
  - $[3 \rightarrow 2]$ 없음
- 도착점이 $3$번 상태일 때 $G$가 나올 확률: $0.00576$
  - $[1 \rightarrow 3]$ $0.18 \times 0.1 \times 0.3 = 0.0054$
  - $[2 \rightarrow 3]$ $0.048 \times 0.4 \times 0.3 = 0.00576$
  - $[3 \rightarrow 3]$ 없음

##### 네번째 $B$
- 도착점이 $1$번 상태일 때 $B$가 나올 확률: $0.018$
  - $[1 \rightarrow 1]$ $0.018 \times 0.5 \times 0.2 = 0.0018$
  - $[2 \rightarrow 1]$ 없음
  - $[3 \rightarrow 1]$ 없음
- 도착점이 $2$번 상태일 때 $B$가 나올 확률: $0.00648$
  - $[1 \rightarrow 2]$ $0.018 \times 0.4 \times 0.3 = 0.00216$
  - $[2 \rightarrow 2]$ $0.036 \times 0.6 \times 0.3 = 0.00648$
  - $[3 \rightarrow 2]$ 없음
- 도착점이 $3$번 상태일 때 $B$가 나올 확률: $0.01008$
  - $[1 \rightarrow 3]$ $0.018 \times 0.1 \times 0.7 = 0.0054$
  - $[2 \rightarrow 3]$ $0.036 \times 0.4 \times 0.7 = 0.01008$
  - $[3 \rightarrow 3]$ 없음

이제 최종 확률이 가장 높은 state들을 역으로 되돌아가면서 선택하면 그것이 최적 경로가 된다. 위의 경우는 $1, 1, 2, 3$이 경로가 된다.

#### Sequence Labeling Problem
HMM이 사용되는 한 문제의 예시이다. 시간축 $t$에 따라 어떤 품사가 올지를 예측하는 문제로, 앞에 나온 단어가 무엇인지에 따라 뒤에 영향을 준다.

- Flies like a flower 라는 문장을 봤을 때, 각각이 어떤 품사일 확률이 가장 높은지 구하기

$$\operatorname*{argmax}_{y_{1\sim 4}} P(\text{flies, like, a, flower},\ y_1,\ y_2,\ y_3,\ y_4)$$

![5-4](assets/img/school_ml/ml5-4.png)


### HMM 파이썬 실습
---
> 신발을 $B, B, S, S$로 신고 왔을 때 날씨를 가장 최적으로 예측하시오.
{: .prompt-info}

![5-2](assets/img/school_ml/ml5-2.png){: style="margin-left: auto; margin-right: auto; width: 50%;"}

```py
import numpy as np
from hmmlearn import hmm

states = ["Rainy", "Cloudy", "Sunny"]
n_states = len(states)

observations = ["Boots", "Shoes"]
n_observations = len(observations)

# 시작 확률
start_probability = np.array([0.2, 0.5, 0.3])

# 전이 확률
transition_probability = np.array([
  [0.4, 0.3, 0.3],
  [0.2, 0.6, 0.2],
  [0.1, 0.1, 0.8]
])

# 관측 확률
emission_probability = np.array([
  [0.8, 0.2],
  [0.5, 0.5],
  [0.1, 0.9]
])

# 모델 만들기
model = hmm.MultinomialHMM(n_components=n_states)
model.startprob_ = start_probability
model.transmat_ = transition_probability
model.emissionprob_ = emission_probability

# 관측 입력
input = [0, 0, 1, 1]

# HMM 모델 호출
hmm_input = np.atleast_2d(input).T
logprob, sequence = model.decode(hmm_input)

print("Input :", ", ".join(map(lambda x: observations[x], input)))
print("Output:", ", ".join(map(lambda x: states[x], sequence)))
print("Prob. :", logprob)
```

1. 여기서는 시작 확률을 명시적으로 제공하였다. Rainy로 시작할 확률은 $0.2$, Cloudy는 $0.5$, Sunny는 $0.3$이다.
2. HMM 모델에 시작확률 `startprob_`, 전이 화률 `transmat_`, 관측 확률 `emissionprob_`을 제공한다.
3. input 값을 `[[0], [0], [1], [1]]` 와 같은 형태로 넣어주기 위해 2차원 배열의 전치행렬로 변환해준다. (HMM에서는 입력으로 각 관측치가 행으로 들어가야 한다.)
4. 최적의 sequence (문제의 정답)과 그 시퀀스가 나올 로그 확률 값을 구한다.

#### Result
```text
Input : Boots, Boots, Shoes, Shoes
Output: Rainy, Rainy, Sunny, Sunny
Prob. : -4.609853133892472
```